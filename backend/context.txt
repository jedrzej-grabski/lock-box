File: tests/__init__.py


File: src/backend/models.py
from sqlalchemy import (
    String,
    Boolean,
    Integer,
    Text,
    ForeignKey,
    DateTime,
    BigInteger,
    UniqueConstraint,
)
from sqlalchemy.dialects.postgresql import UUID as PG_UUID, INET, JSONB
from sqlalchemy.orm import Mapped, mapped_column, relationship, declarative_base
from sqlalchemy.sql import func
from datetime import datetime
from uuid import UUID
import uuid

Base = declarative_base()


# ---------------------------
# User
# ---------------------------
class User(Base):
    __tablename__ = "users"

    id: Mapped[UUID] = mapped_column(
        PG_UUID(as_uuid=True), primary_key=True, default=uuid.uuid4
    )
    email: Mapped[str] = mapped_column(String(255), unique=True)
    password_hash: Mapped[str] = mapped_column(Text)
    full_name: Mapped[str | None] = mapped_column(String(255))
    role: Mapped[str] = mapped_column(String(10))  # 'owner' or 'guest'
    is_verified: Mapped[bool] = mapped_column(default=False)
    is_active: Mapped[bool] = mapped_column(default=True)
    is_superuser: Mapped[bool] = mapped_column(default=False)
    created_at: Mapped[datetime] = mapped_column(
        DateTime(timezone=True), server_default=func.now()
    )
    updated_at: Mapped[datetime] = mapped_column(
        DateTime(timezone=True), server_default=func.now(), onupdate=func.now()
    )

    rooms: Mapped[list["DataRoom"]] = relationship(back_populates="owner")
    documents: Mapped[list["Document"]] = relationship(back_populates="uploader")
    shares: Mapped[list["Share"]] = relationship(
        back_populates="user", cascade="all, delete-orphan"
    )


# ---------------------------
# DataRoom
# ---------------------------
class DataRoom(Base):
    __tablename__ = "data_rooms"

    id: Mapped[UUID] = mapped_column(
        PG_UUID(as_uuid=True), primary_key=True, default=uuid.uuid4
    )
    owner_id: Mapped[UUID] = mapped_column(
        PG_UUID(as_uuid=True), ForeignKey("users.id", ondelete="CASCADE")
    )
    name: Mapped[str] = mapped_column(String(255))
    description: Mapped[str | None] = mapped_column(Text)
    created_at: Mapped[datetime] = mapped_column(
        DateTime(timezone=True), server_default=func.now()
    )
    updated_at: Mapped[datetime] = mapped_column(
        DateTime(timezone=True), server_default=func.now(), onupdate=func.now()
    )

    owner: Mapped["User"] = relationship(back_populates="rooms")
    documents: Mapped[list["Document"]] = relationship(back_populates="data_room")
    invites: Mapped[list["Invite"]] = relationship(back_populates="data_room")
    shares: Mapped[list["Share"]] = relationship(back_populates="data_room")


# ---------------------------
# Document
# ---------------------------
class Document(Base):
    __tablename__ = "documents"

    id: Mapped[UUID] = mapped_column(
        PG_UUID(as_uuid=True), primary_key=True, default=uuid.uuid4
    )
    data_room_id: Mapped[UUID] = mapped_column(
        PG_UUID(as_uuid=True),
        ForeignKey("data_rooms.id", ondelete="CASCADE"),
    )
    uploaded_by: Mapped[UUID] = mapped_column(
        PG_UUID(as_uuid=True), ForeignKey("users.id")
    )
    filename: Mapped[str] = mapped_column(String(255))
    content_type: Mapped[str] = mapped_column(String(100))
    size_bytes: Mapped[int] = mapped_column(BigInteger)
    sha256_hash: Mapped[str | None] = mapped_column(String(64))
    storage_key: Mapped[str] = mapped_column(Text)
    uploaded_at: Mapped[datetime] = mapped_column(
        DateTime(timezone=True), server_default=func.now()
    )

    data_room: Mapped["DataRoom"] = relationship(back_populates="documents")
    uploader: Mapped["User"] = relationship(back_populates="documents")


# ---------------------------
# Invite
# ---------------------------
class Invite(Base):
    __tablename__ = "invites"

    id: Mapped[UUID] = mapped_column(
        PG_UUID(as_uuid=True), primary_key=True, default=uuid.uuid4
    )
    data_room_id: Mapped[UUID] = mapped_column(
        PG_UUID(as_uuid=True),
        ForeignKey("data_rooms.id", ondelete="CASCADE"),
    )
    token_hash: Mapped[str] = mapped_column(String(64), unique=True)
    created_by: Mapped[UUID] = mapped_column(
        PG_UUID(as_uuid=True), ForeignKey("users.id")
    )
    allowed_email: Mapped[str | None] = mapped_column(String(255))
    max_uses: Mapped[int | None] = mapped_column(Integer)
    uses_count: Mapped[int] = mapped_column(Integer, default=0)
    expires_at: Mapped[datetime | None] = mapped_column(DateTime(timezone=True))
    revoked: Mapped[bool | None] = mapped_column(Boolean, default=False)
    created_at: Mapped[datetime] = mapped_column(
        DateTime(timezone=True), server_default=func.now()
    )

    data_room: Mapped["DataRoom"] = relationship(back_populates="invites")


# ---------------------------
# Share
# ---------------------------
class Share(Base):
    __tablename__ = "shares"
    __table_args__ = (
        UniqueConstraint("data_room_id", "user_id", name="uix_data_room_user"),
    )

    id: Mapped[UUID] = mapped_column(
        PG_UUID(as_uuid=True), primary_key=True, default=uuid.uuid4
    )
    data_room_id: Mapped[UUID] = mapped_column(
        PG_UUID(as_uuid=True),
        ForeignKey("data_rooms.id", ondelete="CASCADE"),
    )
    user_id: Mapped[UUID] = mapped_column(
        PG_UUID(as_uuid=True), ForeignKey("users.id", ondelete="CASCADE")
    )
    invite_id: Mapped[UUID | None] = mapped_column(
        PG_UUID(as_uuid=True), ForeignKey("invites.id")
    )
    role: Mapped[str] = mapped_column(String(10))  # 'owner' or 'guest'
    expires_at: Mapped[datetime | None] = mapped_column(DateTime(timezone=True))
    revoked: Mapped[bool | None] = mapped_column(Boolean, default=False)
    created_at: Mapped[datetime] = mapped_column(
        DateTime(timezone=True), server_default=func.now()
    )

    data_room: Mapped["DataRoom"] = relationship(back_populates="shares")
    user: Mapped["User"] = relationship(back_populates="shares")


# ---------------------------
# RefreshToken
# ---------------------------
class RefreshToken(Base):
    __tablename__ = "refresh_tokens"

    id: Mapped[UUID] = mapped_column(
        PG_UUID(as_uuid=True), primary_key=True, default=uuid.uuid4
    )
    user_id: Mapped[UUID] = mapped_column(
        PG_UUID(as_uuid=True), ForeignKey("users.id", ondelete="CASCADE")
    )
    jti: Mapped[UUID] = mapped_column(PG_UUID(as_uuid=True), unique=True)
    issued_at: Mapped[datetime | None] = mapped_column(
        DateTime(timezone=True), server_default=func.now()
    )
    expires_at: Mapped[datetime] = mapped_column(DateTime(timezone=True))
    revoked: Mapped[bool | None] = mapped_column(Boolean, default=False)
    replaced_by: Mapped[UUID | None] = mapped_column(
        PG_UUID(as_uuid=True), ForeignKey("refresh_tokens.id")
    )


# ---------------------------
# AuditLog
# ---------------------------
class AuditLog(Base):
    __tablename__ = "audit_logs"

    id: Mapped[UUID] = mapped_column(
        PG_UUID(as_uuid=True), primary_key=True, default=uuid.uuid4
    )
    user_id: Mapped[UUID | None] = mapped_column(
        PG_UUID(as_uuid=True), ForeignKey("users.id")
    )
    action: Mapped[str] = mapped_column(String(50))
    object_type: Mapped[str | None] = mapped_column(String(50))
    object_id: Mapped[UUID | None] = mapped_column(PG_UUID(as_uuid=True))
    ip_address: Mapped[str | None] = mapped_column(INET)
    user_agent: Mapped[str | None] = mapped_column(Text)
    details: Mapped[dict | None] = mapped_column(JSONB)
    created_at: Mapped[datetime] = mapped_column(
        DateTime(timezone=True), server_default=func.now()
    )


File: src/backend/db.py
from sqlalchemy.ext.asyncio import create_async_engine, async_sessionmaker
from src.backend.config import settings

engine = create_async_engine(settings.DATABASE_URL, echo=True, future=True)
AsyncSessionLocal = async_sessionmaker(engine, expire_on_commit=False)


# Dependency for FastAPI
async def get_db():
    async with AsyncSessionLocal() as session:
        yield session


File: src/backend/schemas.py


File: src/backend/__init__.py


File: src/backend/config.py
from pathlib import Path
from typing import final
from pydantic_settings import BaseSettings


@final
class Settings(BaseSettings):
    ENV: str = "development"
    APP_HOST: str = "0.0.0.0"
    APP_PORT: int = 8000
    API_PREFIX: str = "/api/v1"
    FRONTEND_BASE: str = "https://<placeholder>"

    DATABASE_URL: str = ""
    JWT_PRIVATE_KEY_PATH: str = ""
    JWT_PUBLIC_KEY_PATH: str = ""
    ACCESS_TOKEN_EXPIRES_MINUTES: int = 15
    REFRESH_TOKEN_EXPIRES_DAYS: int = 7
    JWT_ALGORITHM: str = "RS256"
    JWT_ISSUER: str = "lockbox"

    INVITE_TOKEN_HMAC_SECRET: str = "change-me-please"

    S3_BUCKET: str = ""
    S3_REGION: str = ""
    S3_ACCESS_KEY_ID: str = ""
    S3_SECRET_ACCESS_KEY: str = ""
    S3_ENDPOINT_URL: str | None = None

    PASSWORD_HASHING_SCHEME: str = "argon2"

    EMAIL_FROM: str = "no-reply@lockbox.com"
    EMAIL_VERIFICATION_EXPIRY_HOURS: int = 48

    class Config:
        env_file = str(Path(__file__).resolve().parent.parent.parent.parent / ".env")


settings = Settings()


File: src/backend/main.py
from typing import Annotated

from fastapi import FastAPI
from fastapi.middleware.cors import CORSMiddleware
from fastapi.params import Depends
from sqlalchemy import text
from sqlalchemy.ext.asyncio import AsyncSession

from src.backend.api import documents
from src.backend.api import invites
from src.backend.config import settings
from src.backend.db import get_db
from src.backend.api import auth
from src.backend.api import rooms


app = FastAPI(title="LockBox", version="0.1.0")

# CORS for frontend
app.add_middleware(
    CORSMiddleware,
    allow_origins=[settings.FRONTEND_BASE],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

app.include_router(auth.router, prefix="/api/v1/auth", tags=["auth"])
app.include_router(rooms.router, prefix="/api/v1/rooms", tags=["rooms"])
app.include_router(
    documents.router, prefix="/api/v1", tags=["documents"]
)  # documents already has prefix /rooms/{room_id}/documents so mount under /api/v1
app.include_router(invites.router, prefix="/api/v1/invites", tags=["invites"])


@app.get("/health")
async def health_check():
    return {"status": "ok"}


@app.get("/db-test")
async def db_test(db: Annotated[AsyncSession, Depends(get_db)]):
    result = await db.execute(text("SELECT 1"))
    return {"result": result.scalar()}


File: src/backend/utils/audit.py
# src/backend/utils/audit.py
from datetime import datetime, timezone
from typing import Any, Optional
from sqlalchemy.ext.asyncio import AsyncSession
from src.backend.models import AuditLog


async def log_audit(
    db: AsyncSession,
    user_id: Optional[str],
    action: str,
    object_type: Optional[str] = None,
    object_id: Optional[str] = None,
    *,
    details: Optional[dict[str, Any]] = None,
    request: Any = None,
    ip_address: Optional[str] = None,
    user_agent: Optional[str] = None,
) -> None:
    """
    Unified audit logger.
    If FastAPI `request` is provided, extracts IP and user-agent automatically.
    """
    if request is not None:
        if ip_address is None and getattr(request, "client", None):
            ip_address = request.client.host
        if user_agent is None:
            user_agent = request.headers.get("user-agent")

    log = AuditLog(
        user_id=user_id,
        action=action,
        object_type=object_type,
        object_id=object_id,
        ip_address=ip_address,
        user_agent=user_agent,
        details=details or {},
        created_at=datetime.now(timezone.utc),
    )
    db.add(log)


File: src/backend/utils/security.py
from passlib.context import CryptContext
from src.backend.config import settings

pwd_context = CryptContext(
    schemes=[settings.PASSWORD_HASHING_SCHEME], deprecated="auto"
)


def hash_password(password: str) -> str:
    return pwd_context.hash(password)


def verify_password(password: str, hashed: str) -> bool:
    return pwd_context.verify(password, hashed)


File: src/backend/utils/dependencies.py
# src/backend/utils/dependencies.py
"""
Centralized FastAPI dependencies for authentication and access control.

Uses existing JWT helper from src/backend/services/jwt.py.
"""

from typing import Optional
from fastapi import Depends, HTTPException, Request
from fastapi.security import HTTPBearer, HTTPAuthorizationCredentials
from sqlalchemy.ext.asyncio import AsyncSession
from sqlalchemy import select
from datetime import datetime, timezone

# Import project modules
from src.backend.db import get_db
from src.backend.models import User, DataRoom, Share
from src.backend.services.jwt import verify_token  # <-- use your existing helper

security = HTTPBearer(auto_error=False)


async def get_current_user(
    credentials: Optional[HTTPAuthorizationCredentials] = Depends(security),
    db: AsyncSession = Depends(get_db),
):
    """
    Extract user from Bearer token.
    Relies on src/backend/services/jwt.verify_token() to validate RS256 signature.
    """
    if not credentials:
        raise HTTPException(status_code=401, detail="Missing authorization header")

    token = credentials.credentials
    payload = verify_token(token)  # your helper returns payload or raises HTTPException
    user_id = payload.get("sub")
    if not user_id:
        raise HTTPException(status_code=401, detail="Invalid token payload")

    user = await db.get(User, user_id)
    if not user:
        raise HTTPException(status_code=401, detail="User not found")
    if not user.is_active:
        raise HTTPException(status_code=401, detail="User inactive")
    if not user.is_verified:
        raise HTTPException(status_code=401, detail="Email not verified")

    return user


async def require_superuser(user: User = Depends(get_current_user)):
    if not user.is_superuser:
        raise HTTPException(status_code=403, detail="Superuser access required")
    return user


async def require_room_access(
    room_id: str,
    user: User = Depends(get_current_user),
    db: AsyncSession = Depends(get_db),
    require_role: Optional[str] = None,
):
    """
    Check if the current user can access a room.
      - Superuser → allow
      - Room owner → allow
      - Else must have active Share (not revoked, not expired)
      - If require_role provided → Share.role must match
    """
    if user.is_superuser:
        room = await db.get(DataRoom, room_id)
        if not room:
            raise HTTPException(status_code=404, detail="Data room not found")
        return {"room": room, "share": None}

    room = await db.get(DataRoom, room_id)
    if not room:
        raise HTTPException(status_code=404, detail="Data room not found")

    # Owner check
    if str(room.owner_id) == str(user.id):
        return {"room": room, "share": None}

    # Otherwise check share record
    q = await db.execute(
        select(Share).where(
            Share.user_id == user.id,
            Share.data_room_id == room_id,
            Share.revoked == False,
        )
    )
    share = q.scalars().first()
    if not share:
        raise HTTPException(status_code=403, detail="Access denied")

    # Expiry check
    if share.expires_at and share.expires_at <= datetime.now(timezone.utc):
        raise HTTPException(status_code=403, detail="Share expired")

    # Role check
    if require_role and share.role != require_role:
        raise HTTPException(status_code=403, detail="Insufficient role")

    return {"room": room, "share": share}


File: src/backend/api/invites.py
# src/backend/api/invites.py
"""
Invite management:
- POST /invites/    -> create invite for a specific data_room_id (owner only)
- POST /invites/accept?token=... -> accept invite (after login); creates Share (guest)
- POST /invites/{invite_id}/revoke -> revoke invite (owner only)
"""

from fastapi import APIRouter, Depends, HTTPException, Request, Query
from pydantic import BaseModel, EmailStr
from sqlalchemy.ext.asyncio import AsyncSession
from sqlalchemy import select, update
from datetime import datetime, timezone, timedelta
from uuid import uuid4
import hashlib
import hmac
import secrets

# adjust imports to your project
from src.backend.db import get_db  # yields AsyncSession
from src.backend.models import Invite, DataRoom, Share  # noqa: E402
from src.backend.utils.dependencies import get_current_user  # noqa: E402
from src.backend.utils.audit import log_audit  # noqa: E402
from src.backend.config import settings  # noqa: E402

router = APIRouter(prefix="/invites", tags=["invites"])


def _hash_token(raw_token: str, secret: str) -> str:
    # HMAC-SHA256 hex digest
    mac = hmac.new(secret.encode(), raw_token.encode(), hashlib.sha256)
    return mac.hexdigest()


class InviteCreateRequest(BaseModel):
    data_room_id: str
    allowed_email: EmailStr | None = None
    max_uses: int | None = None  # None = unlimited
    expires_hours: int | None = None  # None = no expiry
    single_use: bool = False


class InviteListItem(BaseModel):
    id: str
    allowed_email: str | None
    max_uses: int | None
    uses_count: int
    expires_at: datetime | None
    revoked: bool


class InviteCreateResponse(BaseModel):
    invite_id: str
    raw_token: str  # raw token shown once to owner (store only hash)
    invite_link_path: str


@router.get("/room/{room_id}", response_model=list[InviteListItem])
async def list_invites_for_room(
    room_id: str, db: AsyncSession = Depends(get_db), user=Depends(get_current_user)
):
    # verify owner or superuser
    qroom = await db.execute(select(DataRoom).where(DataRoom.id == room_id))
    room = qroom.scalars().first()
    if not room:
        raise HTTPException(status_code=404, detail="Data room not found")
    if not (getattr(user, "is_superuser", False) or str(room.owner_id) == str(user.id)):
        raise HTTPException(status_code=403, detail="Only owner can list invites")
    res = await db.execute(select(Invite).where(Invite.data_room_id == room_id))
    invites = res.scalars().all()
    return [
        InviteListItem(
            id=str(i.id),
            allowed_email=i.allowed_email,
            max_uses=i.max_uses,
            uses_count=i.uses_count,
            expires_at=i.expires_at,
            revoked=bool(i.revoked),
        )
        for i in invites
    ]


@router.post("/", response_model=InviteCreateResponse)
async def create_invite(
    req: InviteCreateRequest,
    request: Request,
    db: AsyncSession = Depends(get_db),
    user=Depends(get_current_user),
):
    # verify room and ownership
    q = await db.execute(select(DataRoom).where(DataRoom.id == req.data_room_id))
    room = q.scalars().first()
    if not room:
        raise HTTPException(status_code=404, detail="Data room not found")
    if not (getattr(user, "is_superuser", False) or str(room.owner_id) == str(user.id)):
        raise HTTPException(
            status_code=403, detail="Only room owner can create invites"
        )

    # generate raw token and store hash
    raw_token = secrets.token_urlsafe(32)
    token_hash = _hash_token(raw_token, settings.INVITE_TOKEN_HMAC_SECRET)

    expires_at = None
    if req.expires_hours:
        expires_at = datetime.now(timezone.utc) + timedelta(hours=req.expires_hours)

    max_uses = req.max_uses
    if req.single_use:
        max_uses = 1

    invite = Invite(
        data_room_id=req.data_room_id,
        token_hash=token_hash,
        created_by=user.id,
        allowed_email=req.allowed_email,
        max_uses=max_uses,
        uses_count=0,
        expires_at=expires_at,
        revoked=False,
        created_at=datetime.now(timezone.utc),
    )
    db.add(invite)
    await db.flush()
    await log_audit(
        db,
        str(user.id),
        "create_invite",
        "invite",
        str(invite.id),
        details={"data_room_id": req.data_room_id, "max_uses": max_uses},
        request=request,
    )
    await db.commit()

    invite_link_path = f"/invites/accept?token={raw_token}"
    return InviteCreateResponse(
        invite_id=str(invite.id), raw_token=raw_token, invite_link_path=invite_link_path
    )


@router.post("/accept")
async def accept_invite(
    request: Request,
    token: str = Query(...),
    db: AsyncSession = Depends(get_db),
    user=Depends(get_current_user),
):
    """
    Accept an invite using the raw token (user must be authenticated).
    Validations:
      - invite exists (by token hash), not revoked, not expired
      - allowed_email if present must match user.email
      - max_uses if present must not be exceeded
    On success: create Share(user_id, data_room_id, role='guest', invite_id=invite.id), increment uses_count, audit.
    """
    token_hash = _hash_token(token, settings.INVITE_TOKEN_HMAC_SECRET)
    q = await db.execute(select(Invite).where(Invite.token_hash == token_hash))
    invite = q.scalars().first()
    if not invite:
        raise HTTPException(status_code=404, detail="Invite not found or invalid")

    if invite.revoked:
        raise HTTPException(status_code=403, detail="Invite revoked")

    if invite.expires_at and invite.expires_at <= datetime.now(timezone.utc):
        raise HTTPException(status_code=403, detail="Invite expired")

    if invite.allowed_email and invite.allowed_email.lower() != user.email.lower():
        raise HTTPException(
            status_code=403, detail="Invite restricted to a different email"
        )

    if invite.max_uses is not None and (invite.uses_count or 0) >= invite.max_uses:
        raise HTTPException(status_code=403, detail="Invite max uses exceeded")

    # create share if not already present
    # note: unique (data_room_id, user_id) constraint exists in schema
    existing_q = await db.execute(
        select(Share).where(
            Share.data_room_id == invite.data_room_id, Share.user_id == user.id
        )
    )
    existing_share = existing_q.scalars().first()
    if existing_share:
        # if previously revoked, return error; otherwise just return OK
        if existing_share.revoked:
            raise HTTPException(
                status_code=403, detail="Your access was revoked for this room"
            )
        # else already a member
        return {"detail": "Already member of the room"}

    new_share = Share(
        data_room_id=invite.data_room_id,
        user_id=user.id,
        invite_id=invite.id,
        role="guest",
        expires_at=None,
        revoked=False,
        created_at=datetime.now(timezone.utc),
    )
    db.add(new_share)

    # increment uses_count atomically (simple approach: update then commit)
    invite.uses_count = (invite.uses_count or 0) + 1

    await log_audit(
        db,
        str(user.id),
        "accept_invite",
        "invite",
        str(invite.id),
        details={"data_room_id": str(invite.data_room_id)},
        request=request,
    )
    await db.commit()
    return {"detail": "Invite accepted", "data_room_id": str(invite.data_room_id)}


@router.post("/{invite_id}/revoke")
async def revoke_invite(
    invite_id: str,
    request: Request,
    db: AsyncSession = Depends(get_db),
    user=Depends(get_current_user),
):
    """
    Revoke invite. Only room owner or superuser may revoke.
    """
    q = await db.execute(select(Invite).where(Invite.id == invite_id))
    invite = q.scalars().first()
    if not invite:
        raise HTTPException(status_code=404, detail="Invite not found")

    # check ownership of room
    qroom = await db.execute(select(DataRoom).where(DataRoom.id == invite.data_room_id))
    room = qroom.scalars().first()
    if not room:
        raise HTTPException(status_code=404, detail="Data room for invite not found")

    if not (getattr(user, "is_superuser", False) or str(room.owner_id) == str(user.id)):
        raise HTTPException(
            status_code=403, detail="Only room owner or superuser can revoke invite"
        )

    invite.revoked = True
    await log_audit(
        db,
        str(user.id),
        "revoke_invite",
        "invite",
        str(invite.id),
        details={"data_room_id": str(invite.data_room_id)},
        request=request,
    )
    await db.commit()
    return {"detail": "Invite revoked"}


File: src/backend/api/rooms.py
from fastapi import APIRouter, Depends, HTTPException, Request
from pydantic import BaseModel
from sqlalchemy.ext.asyncio import AsyncSession
from sqlalchemy import select
from datetime import datetime, timezone

from src.backend.db import get_db
from src.backend.models import DataRoom, Share
from src.backend.utils.dependencies import get_current_user
from src.backend.utils.audit import log_audit

router = APIRouter(prefix="/rooms", tags=["rooms"])


class CreateRoomRequest(BaseModel):
    name: str
    description: str | None = None


class ShareListItem(BaseModel):
    id: str
    user_id: str
    role: str
    expires_at: datetime | None
    revoked: bool
    created_at: datetime


class RoomOut(BaseModel):
    id: str
    owner_id: str
    name: str
    description: str | None
    created_at: datetime


@router.get("/", response_model=list[RoomOut])
async def list_rooms(
    db: AsyncSession = Depends(get_db), user=Depends(get_current_user)
):
    """
    List rooms for current user:
      - superuser: all rooms
      - owner: rooms they own + rooms shared
      - guest: rooms shared with them
    """
    from src.backend.models import Share

    if getattr(user, "is_superuser", False):
        result = await db.execute(select(DataRoom))
        rooms = result.scalars().all()
    elif getattr(user, "role", None) == "owner":
        # owned rooms
        res1 = await db.execute(select(DataRoom).where(DataRoom.owner_id == user.id))
        owned = res1.scalars().all()
        # shared rooms
        res2 = await db.execute(
            select(DataRoom)
            .join(Share)
            .where(Share.user_id == user.id, Share.revoked == False)
        )
        shared = res2.scalars().all()
        # combine unique
        room_set = {r.id: r for r in list(set(list(owned) + list(shared)))}
        rooms = list(room_set.values())
    else:
        res = await db.execute(
            select(DataRoom)
            .join(Share)
            .where(Share.user_id == user.id, Share.revoked == False)
        )
        rooms = res.scalars().all()

    return [
        RoomOut(
            id=str(r.id),
            owner_id=str(r.owner_id),
            name=r.name,
            description=r.description,
            created_at=r.created_at,
        )
        for r in rooms
    ]


@router.post("/", response_model=RoomOut)
async def create_room(
    req: CreateRoomRequest,
    request: Request,
    db: AsyncSession = Depends(get_db),
    user=Depends(get_current_user),
):
    """
    Create a data room. Only users with role 'owner' or superuser may create rooms.
    On creation, create a Share record granting the owner 'owner' role on the room.
    """
    if not (
        getattr(user, "is_superuser", False) or getattr(user, "role", None) == "owner"
    ):
        raise HTTPException(status_code=403, detail="Only owners may create rooms")

    room = DataRoom(
        owner_id=user.id,
        name=req.name,
        description=req.description,
        created_at=datetime.now(timezone.utc),
    )
    db.add(room)
    await db.flush()  # get room.id

    # create owner Share
    owner_share = Share(
        data_room_id=room.id,
        user_id=user.id,
        invite_id=None,
        role="owner",
        expires_at=None,
        revoked=False,
        created_at=datetime.now(timezone.utc),
    )
    db.add(owner_share)
    await log_audit(
        db,
        str(user.id),
        "create_room",
        "data_room",
        str(room.id),
        details={"name": req.name},
        request=request,
    )
    await db.commit()
    await db.refresh(room)

    return RoomOut(
        id=str(room.id),
        owner_id=str(room.owner_id),
        name=room.name,
        description=room.description,
        created_at=room.created_at,
    )


@router.post("/{room_id}/shares/{user_id}/revoke")
async def revoke_share(
    room_id: str,
    request: Request,
    user_id: str,
    db: AsyncSession = Depends(get_db),
    user=Depends(get_current_user),
):
    """
    Owner can revoke a user's access to their room.
    """
    # verify room exists and owner
    q = await db.execute(select(DataRoom).where(DataRoom.id == room_id))
    room = q.scalars().first()
    if not room:
        raise HTTPException(status_code=404, detail="Room not found")

    if not (getattr(user, "is_superuser", False) or str(room.owner_id) == str(user.id)):
        raise HTTPException(status_code=403, detail="Only room owner can revoke access")

    # fetch share
    from src.backend.models import Share  # local import to avoid cycle

    q2 = await db.execute(
        select(Share).where(Share.data_room_id == room_id, Share.user_id == user_id)
    )
    share = q2.scalars().first()
    if not share:
        raise HTTPException(status_code=404, detail="Share not found")

    share.revoked = True
    await log_audit(
        db,
        str(user.id),
        "revoke_access",
        "share",
        str(share.id),
        details={"revoked_user_id": user_id},
        request=request,
    )
    await db.commit()
    return {"detail": "Access revoked"}


@router.get("/{room_id}/shares", response_model=list[ShareListItem])
async def list_shares(
    room_id: str, db: AsyncSession = Depends(get_db), user=Depends(get_current_user)
):
    # only owner or superuser
    qroom = await db.execute(select(DataRoom).where(DataRoom.id == room_id))
    room = qroom.scalars().first()
    if not room:
        raise HTTPException(status_code=404, detail="Data room not found")
    if not (getattr(user, "is_superuser", False) or str(room.owner_id) == str(user.id)):
        raise HTTPException(status_code=403, detail="Only owner can list shares")
    from src.backend.models import Share

    res = await db.execute(select(Share).where(Share.data_room_id == room_id))
    shares = res.scalars().all()
    return [
        ShareListItem(
            id=str(s.id),
            user_id=str(s.user_id),
            role=s.role,
            expires_at=s.expires_at,
            revoked=bool(s.revoked),
            created_at=s.created_at,
        )
        for s in shares
    ]


File: src/backend/api/auth.py
from fastapi import APIRouter, Depends, HTTPException, Request
from pydantic import BaseModel, EmailStr
from sqlalchemy.ext.asyncio import AsyncSession
from sqlalchemy import select
from datetime import datetime, timezone

from src.backend.db import get_db
from src.backend.models import User, RefreshToken
from src.backend.utils.audit import log_audit
from src.backend.utils.security import hash_password, verify_password
from src.backend.services.jwt import (
    create_access_token,
    create_refresh_token,
    verify_token,
)

router = APIRouter(prefix="/auth", tags=["auth"])


# ------------------------
# Schemas
# ------------------------
class RegisterRequest(BaseModel):
    email: EmailStr
    password: str
    full_name: str | None = None
    role: str  # 'owner' or 'guest'


class LoginRequest(BaseModel):
    email: EmailStr
    password: str


class TokenResponse(BaseModel):
    access_token: str
    refresh_token: str
    token_type: str = "bearer"
    access_expires_in: int


class RefreshRequest(BaseModel):
    refresh_token: str


class LogoutRequest(BaseModel):
    refresh_token: str


# ------------------------
# Endpoints
# ------------------------


@router.post("/register", response_model=TokenResponse)
async def register(
    req: RegisterRequest, request: Request, db: AsyncSession = Depends(get_db)
):
    if req.role not in ("owner", "guest"):
        raise HTTPException(status_code=400, detail="Invalid role")

    q = await db.execute(select(User).where(User.email == req.email.lower()))
    if q.scalars().first():
        raise HTTPException(status_code=400, detail="Email already registered")

    user = User(
        email=req.email.lower(),
        password_hash=hash_password(req.password),
        full_name=req.full_name,
        role=req.role,
        is_verified=True,
        is_active=True,
        is_superuser=False,
    )
    db.add(user)
    await db.flush()

    access_token, access_expires_in = create_access_token(str(user.id))
    refresh_token, jti, refresh_expires_at = create_refresh_token(str(user.id))

    db.add(
        RefreshToken(
            user_id=user.id,
            jti=jti,
            issued_at=datetime.now(timezone.utc),
            expires_at=refresh_expires_at,
            revoked=False,
        )
    )

    await log_audit(
        db, str(user.id), "user_register", "user", str(user.id), request=request
    )
    await db.commit()

    return TokenResponse(
        access_token=access_token,
        refresh_token=refresh_token,
        access_expires_in=access_expires_in,
    )


@router.post("/login", response_model=TokenResponse)
async def login(
    req: LoginRequest, request: Request, db: AsyncSession = Depends(get_db)
):
    q = await db.execute(select(User).where(User.email == req.email.lower()))
    user = q.scalars().first()
    if not user or not verify_password(req.password, user.password_hash):
        raise HTTPException(status_code=401, detail="Invalid credentials")

    if not user.is_active:
        raise HTTPException(status_code=401, detail="User inactive")
    if not user.is_verified:
        raise HTTPException(status_code=401, detail="Email not verified")

    access_token, access_expires_in = create_access_token(str(user.id))
    refresh_token, jti, refresh_expires_at = create_refresh_token(str(user.id))

    db.add(
        RefreshToken(
            user_id=user.id,
            jti=jti,
            issued_at=datetime.now(timezone.utc),
            expires_at=refresh_expires_at,
            revoked=False,
        )
    )

    await log_audit(
        db, str(user.id), "user_login", "user", str(user.id), request=request
    )
    await db.commit()

    return TokenResponse(
        access_token=access_token,
        refresh_token=refresh_token,
        access_expires_in=access_expires_in,
    )


@router.post("/refresh", response_model=TokenResponse)
async def refresh(
    req: RefreshRequest, request: Request, db: AsyncSession = Depends(get_db)
):
    payload = verify_token(req.refresh_token)
    if payload.get("type") != "refresh":
        raise HTTPException(status_code=401, detail="Invalid token type")

    user_id = payload.get("sub")
    jti = payload.get("jti")

    if not user_id:
        raise HTTPException(status_code=401, detail="Invalid token payload")

    q = await db.execute(select(RefreshToken).where(RefreshToken.jti == jti))
    old_rt = q.scalars().first()
    if not old_rt or old_rt.revoked:
        raise HTTPException(status_code=401, detail="Invalid refresh token")

    # check expiry
    from datetime import datetime as dt, timezone as _tz

    if old_rt.expires_at and old_rt.expires_at <= dt.now(_tz.utc):
        old_rt.revoked = True
        await db.commit()
        raise HTTPException(status_code=401, detail="Refresh token expired")

    access_token, access_expires_in = create_access_token(user_id)
    new_refresh_token, new_jti, new_expires_at = create_refresh_token(user_id)

    new_rt = RefreshToken(
        user_id=user_id,
        jti=new_jti,
        issued_at=dt.now(_tz.utc),
        expires_at=new_expires_at,
        revoked=False,
    )
    db.add(new_rt)
    await db.flush()  # ensure new_rt.id is available

    old_rt.revoked = True
    old_rt.replaced_by = new_rt.id

    await log_audit(
        db,
        str(user_id),
        "refresh_token",
        "refresh_token",
        str(old_rt.id),
        request=request,
    )
    await db.commit()

    return TokenResponse(
        access_token=access_token,
        refresh_token=new_refresh_token,
        access_expires_in=access_expires_in,
    )


@router.post("/logout")
async def logout(
    req: LogoutRequest, request: Request, db: AsyncSession = Depends(get_db)
):
    payload = verify_token(req.refresh_token)
    user_id = payload.get("sub")
    jti = payload.get("jti")

    q = await db.execute(select(RefreshToken).where(RefreshToken.jti == jti))
    rt = q.scalars().first()
    if rt:
        rt.revoked = True
        await log_audit(
            db, str(user_id), "logout", "refresh_token", str(rt.id), request=request
        )
        await db.commit()

    return {"detail": "Logged out"}


File: src/backend/api/documents.py
from fastapi import APIRouter, Depends, HTTPException, Request
from pydantic import BaseModel
from sqlalchemy.ext.asyncio import AsyncSession
from sqlalchemy import select
from uuid import uuid4
from datetime import datetime, timezone


from src.backend.db import get_db
from src.backend.models import DataRoom, Document
from src.backend.services import s3 as s3svc
from src.backend.config import settings
from src.backend.utils.dependencies import (
    get_current_user,
)
from src.backend.utils.audit import log_audit
from botocore.exceptions import ClientError

router = APIRouter(prefix="/rooms/{room_id}/documents", tags=["documents"])


class PresignResponse(BaseModel):
    upload_url: str
    storage_key: str
    expires_in: int


class ConfirmUploadRequest(BaseModel):
    filename: str
    content_type: str
    size_bytes: int
    storage_key: str
    sha256_hash: str | None = None


class DocumentOut(BaseModel):
    id: str
    filename: str
    content_type: str
    size_bytes: int
    uploaded_at: datetime
    uploaded_by: str


class DownloadResponse(BaseModel):
    download_url: str
    expires_in: int


@router.get("/", response_model=list[DocumentOut])
async def list_documents_in_room(
    room_id: str,
    db: AsyncSession = Depends(get_db),
    user=Depends(get_current_user),
):
    """
    List documents in a room (owner/guest/superuser).
    """
    # check access (reuse require_room_access)
    from src.backend.utils.dependencies import (
        require_room_access as require_room_access_fn,
    )

    await require_room_access_fn(room_id, user=user, db=db)

    q = await db.execute(
        select(Document)
        .where(Document.data_room_id == room_id)
        .order_by(Document.uploaded_at.desc())
    )
    docs = q.scalars().all()
    return [
        DocumentOut(
            id=str(d.id),
            filename=d.filename,
            content_type=d.content_type,
            size_bytes=d.size_bytes,
            uploaded_at=d.uploaded_at,
            uploaded_by=str(d.uploaded_by),
        )
        for d in docs
    ]


@router.post("/presign", response_model=PresignResponse)
async def presign_upload(
    room_id: str,
    request: Request,
    db: AsyncSession = Depends(get_db),
    user=Depends(get_current_user),
):
    # verify room exists and user is owner of room or superuser
    q = await db.execute(select(DataRoom).where(DataRoom.id == room_id))
    room = q.scalars().first()
    if not room:
        raise HTTPException(status_code=404, detail="Room not found")

    if not (getattr(user, "is_superuser", False) or str(room.owner_id) == str(user.id)):
        raise HTTPException(
            status_code=403, detail="Only room owner can initiate uploads"
        )

    # create storage key
    doc_uuid = uuid4()
    storage_key = f"rooms/{room_id}/documents/{doc_uuid}"
    expires = 300  # 5 minutes

    presigned = s3svc.generate_presigned_put_url(
        settings.S3_BUCKET, storage_key, expires_in=expires
    )

    # audit presign event (note: spec wants audit for file save etc; presign is a major action too)
    await log_audit(
        db,
        str(user.id),
        "presign_upload",
        "data_room",
        room_id,
        details={"storage_key": storage_key},
        request=request,
    )
    await db.commit()

    return PresignResponse(
        upload_url=presigned["url"], storage_key=storage_key, expires_in=expires
    )


@router.post("/confirm", response_model=DocumentOut)
async def confirm_upload(
    room_id: str,
    payload: ConfirmUploadRequest,
    request: Request,
    db: AsyncSession = Depends(get_db),
    user=Depends(get_current_user),
):
    """
    After client uploads to S3 using the presigned URL, the client calls this endpoint with metadata
    to create the Document DB record.
    Only room owner may create Document records.
    """
    # verify room exists
    q = await db.execute(select(DataRoom).where(DataRoom.id == room_id))
    room = q.scalars().first()
    if not room:
        raise HTTPException(status_code=404, detail="Room not found")

    if not (getattr(user, "is_superuser", False) or str(room.owner_id) == str(user.id)):
        raise HTTPException(
            status_code=403, detail="Only room owner can confirm uploads"
        )

    # validate the storage key corresponds to the expected room path
    if not payload.storage_key.startswith(f"rooms/{room_id}/documents/"):
        raise HTTPException(
            status_code=400, detail="storage_key does not belong to room"
        )

    # HEAD the S3 object to validate presence and size
    try:
        meta = s3svc.head_object(settings.S3_BUCKET, payload.storage_key)
    except ClientError:
        raise HTTPException(status_code=400, detail="Uploaded object not found in S3")

    s3_size = int(meta.get("ContentLength", 0))
    if s3_size != payload.size_bytes:
        raise HTTPException(
            status_code=400, detail="Size mismatch between client and S3"
        )

    # create Document record
    new_doc = Document(
        data_room_id=room_id,
        uploaded_by=user.id,
        filename=payload.filename,
        content_type=payload.content_type,
        size_bytes=payload.size_bytes,
        sha256_hash=payload.sha256_hash,
        storage_key=payload.storage_key,
        uploaded_at=datetime.now(timezone.utc),
    )
    db.add(new_doc)
    await db.flush()
    await log_audit(
        db,
        str(user.id),
        "upload_document",
        "document",
        str(new_doc.id),
        details={"filename": payload.filename},
        request=request,
    )
    await db.commit()
    await db.refresh(new_doc)

    return DocumentOut(
        id=str(new_doc.id),
        filename=new_doc.filename,
        content_type=new_doc.content_type,
        size_bytes=new_doc.size_bytes,
        uploaded_at=new_doc.uploaded_at,
        uploaded_by=str(new_doc.uploaded_by),
    )


@router.get("/{doc_id}/download", response_model=DownloadResponse)
async def get_download_url(
    room_id: str,
    request: Request,
    doc_id: str,
    db: AsyncSession = Depends(get_db),
    user=Depends(get_current_user),
):
    """
    Verify access and return presigned GET URL (1 minute TTL).
    Access rules: owner of room, guest with valid Share, or superuser.
    """
    # require_room_access will raise if user cannot access; we call it here to enforce rules
    from src.backend.utils.dependencies import (
        require_room_access as require_room_access_fn,
    )

    access = await require_room_access_fn(room_id, user=user, db=db)
    # Fetch document
    q = await db.execute(
        select(Document).where(Document.id == doc_id, Document.data_room_id == room_id)
    )
    doc = q.scalars().first()
    if not doc:
        raise HTTPException(status_code=404, detail="Document not found")

    expires = 60  # 1 minute
    url = s3svc.generate_presigned_get_url(
        settings.S3_BUCKET, doc.storage_key, expires_in=expires
    )

    await log_audit(
        db, str(user.id), "download_document", "document", str(doc.id), request=request
    )
    await db.commit()

    return DownloadResponse(download_url=url, expires_in=expires)


@router.delete("/{doc_id}", status_code=204)
async def delete_document(
    room_id: str,
    doc_id: str,
    request: Request,
    db: AsyncSession = Depends(get_db),
    user=Depends(get_current_user),
):
    """
    Delete a document: only room owner (or superuser) may delete.
    Removes DB record and attempts to delete object from S3.
    """
    # verify room exists and ownership
    q = await db.execute(select(DataRoom).where(DataRoom.id == room_id))
    room = q.scalars().first()
    if not room:
        raise HTTPException(status_code=404, detail="Room not found")

    if not (getattr(user, "is_superuser", False) or str(room.owner_id) == str(user.id)):
        raise HTTPException(
            status_code=403, detail="Only room owner can delete documents"
        )

    # fetch document
    q2 = await db.execute(
        select(Document).where(Document.id == doc_id, Document.data_room_id == room_id)
    )
    doc = q2.scalars().first()
    if not doc:
        raise HTTPException(status_code=404, detail="Document not found")

    try:
        s3svc.delete_object(settings.S3_BUCKET, doc.storage_key)
    except Exception:
        print("Failed to delete object from S3")

    # delete DB record
    await db.delete(doc)
    await log_audit(
        db,
        str(user.id),
        "delete_document",
        "document",
        str(doc.id),
        details={"filename": doc.filename},
        request=request,
    )
    await db.commit()
    return


File: src/backend/services/jwt.py
# src/backend/services/jwt.py
from datetime import datetime, timedelta, timezone
from jose import jwt, JWTError, ExpiredSignatureError
from fastapi import HTTPException, status
from src.backend.config import settings
import uuid

ALGORITHM = settings.JWT_ALGORITHM


def _load_private_key() -> str:
    """Load RSA private key."""
    with open(settings.JWT_PRIVATE_KEY_PATH, "r") as f:
        return f.read()


def _load_public_key() -> str:
    """Load RSA public key."""
    with open(settings.JWT_PUBLIC_KEY_PATH, "r") as f:
        return f.read()


# -------------------------------
#   Token Creation
# -------------------------------


def create_access_token(user_id: str) -> tuple[str, int]:
    now = datetime.now(timezone.utc)
    expires_at = now + timedelta(minutes=settings.ACCESS_TOKEN_EXPIRES_MINUTES)
    payload = {
        "sub": str(user_id),
        "type": "access",
        "iat": int(now.timestamp()),
        "exp": int(expires_at.timestamp()),
        "iss": settings.JWT_ISSUER,
    }
    token = jwt.encode(payload, _load_private_key(), algorithm=ALGORITHM)
    return token, int((expires_at - now).total_seconds())


def create_refresh_token(user_id: str) -> tuple[str, str, datetime]:
    now = datetime.now(timezone.utc)
    expires_at = now + timedelta(days=settings.REFRESH_TOKEN_EXPIRES_DAYS)
    jti = str(uuid.uuid4())
    payload = {
        "sub": str(user_id),
        "type": "refresh",
        "jti": jti,
        "iat": int(now.timestamp()),
        "exp": int(expires_at.timestamp()),
        "iss": settings.JWT_ISSUER,
    }
    token = jwt.encode(payload, _load_private_key(), algorithm=ALGORITHM)
    return token, jti, expires_at


# -------------------------------
#   Token Verification
# -------------------------------


def verify_token(token: str) -> dict:
    try:
        payload = jwt.decode(
            token,
            _load_public_key(),
            algorithms=[ALGORITHM],
            issuer=settings.JWT_ISSUER,
        )
        return payload
    except ExpiredSignatureError:
        raise HTTPException(
            status_code=status.HTTP_401_UNAUTHORIZED, detail="Token expired"
        )
    except JWTError as e:
        raise HTTPException(
            status_code=status.HTTP_401_UNAUTHORIZED, detail="Invalid token"
        )


File: src/backend/services/s3.py
from typing import Any
import boto3
from botocore.client import Config
from botocore.exceptions import ClientError
import logging

# adjust path to your config/settings module
from src.backend.config import settings  # noqa: E402

logger = logging.getLogger(__name__)

_session = boto3.Session()

_s3_client = _session.client(
    "s3",
    region_name=settings.S3_REGION,
    aws_access_key_id=settings.S3_ACCESS_KEY_ID,
    aws_secret_access_key=settings.S3_SECRET_ACCESS_KEY,
    config=Config(signature_version="s3v4"),
)


def generate_presigned_put_url(
    bucket_name: str,
    key: str,
    expires_in: int = 300,
    extra_fields: dict[str, Any] | None = None,
) -> dict[str, Any]:
    try:
        url = _s3_client.generate_presigned_url(
            ClientMethod="put_object",
            Params={"Bucket": bucket_name, "Key": key},
            ExpiresIn=expires_in,
        )
        return {"url": url}
    except ClientError as e:
        logger.exception("Failed to generate presigned PUT url")
        raise


def generate_presigned_get_url(bucket_name: str, key: str, expires_in: int = 60) -> str:
    """Return a presigned GET URL for the object"""
    try:
        url = _s3_client.generate_presigned_url(
            ClientMethod="get_object",
            Params={"Bucket": bucket_name, "Key": key},
            ExpiresIn=expires_in,
        )
        return url
    except ClientError as e:
        logger.exception("Failed to generate presigned GET url")
        raise


def head_object(bucket_name: str, key: str) -> dict[str, Any]:
    """Return head_object metadata (raises ClientError if not found)"""
    resp = _s3_client.head_object(Bucket=bucket_name, Key=key)
    return resp


def delete_object(bucket_name: str, key: str) -> None:
    """Delete an object from S3 (raises ClientError if failure)"""
    _s3_client.delete_object(Bucket=bucket_name, Key=key)


File: alembic/env.py
import sys
import os
from logging.config import fileConfig

from sqlalchemy import engine_from_config
from sqlalchemy import pool
from alembic import context

sys.path.append(os.path.join(os.path.dirname(__file__), "../"))

from src.backend.models import Base
from src.backend.config import settings

config = context.config

if config.config_file_name:
    fileConfig(config.config_file_name)

config.set_main_option(
    "sqlalchemy.url", settings.DATABASE_URL.replace("+asyncpg", "+psycopg2")
)

target_metadata = Base.metadata


def run_migrations_offline():
    url = config.get_main_option("sqlalchemy.url")
    context.configure(
        url=url,
        target_metadata=target_metadata,
        literal_binds=True,
        dialect_opts={"paramstyle": "named"},
    )
    with context.begin_transaction():
        context.run_migrations()


def run_migrations_online():
    connectable = engine_from_config(
        config.get_section(config.config_ini_section) or {},
        prefix="sqlalchemy.",
        poolclass=pool.NullPool,
    )
    with connectable.connect() as connection:
        context.configure(connection=connection, target_metadata=target_metadata)
        with context.begin_transaction():
            context.run_migrations()


if context.is_offline_mode():
    run_migrations_offline()
else:
    run_migrations_online()


File: alembic/versions/ae385a06b321_initial_schema.py
"""initial schema

Revision ID: ae385a06b321
Revises: 
Create Date: 2025-10-16 23:53:47.705887

"""
from typing import Sequence, Union

from alembic import op
import sqlalchemy as sa
from sqlalchemy.dialects import postgresql

# revision identifiers, used by Alembic.
revision: str = 'ae385a06b321'
down_revision: Union[str, Sequence[str], None] = None
branch_labels: Union[str, Sequence[str], None] = None
depends_on: Union[str, Sequence[str], None] = None


def upgrade() -> None:
    """Upgrade schema."""
    # ### commands auto generated by Alembic - please adjust! ###
    op.create_table('users',
    sa.Column('id', sa.UUID(), nullable=False),
    sa.Column('email', sa.String(length=255), nullable=False),
    sa.Column('password_hash', sa.Text(), nullable=False),
    sa.Column('full_name', sa.String(length=255), nullable=True),
    sa.Column('role', sa.String(length=10), nullable=False),
    sa.Column('is_verified', sa.Boolean(), nullable=True),
    sa.Column('is_active', sa.Boolean(), nullable=True),
    sa.Column('is_superuser', sa.Boolean(), nullable=True),
    sa.Column('created_at', sa.DateTime(timezone=True), server_default=sa.text('now()'), nullable=True),
    sa.Column('updated_at', sa.DateTime(timezone=True), server_default=sa.text('now()'), nullable=True),
    sa.PrimaryKeyConstraint('id'),
    sa.UniqueConstraint('email')
    )
    op.create_table('audit_logs',
    sa.Column('id', sa.UUID(), nullable=False),
    sa.Column('user_id', sa.UUID(), nullable=True),
    sa.Column('action', sa.String(length=50), nullable=False),
    sa.Column('object_type', sa.String(length=50), nullable=True),
    sa.Column('object_id', sa.UUID(), nullable=True),
    sa.Column('ip_address', postgresql.INET(), nullable=True),
    sa.Column('user_agent', sa.Text(), nullable=True),
    sa.Column('details', postgresql.JSONB(astext_type=sa.Text()), nullable=True),
    sa.Column('created_at', sa.DateTime(timezone=True), server_default=sa.text('now()'), nullable=True),
    sa.ForeignKeyConstraint(['user_id'], ['users.id'], ),
    sa.PrimaryKeyConstraint('id')
    )
    op.create_table('data_rooms',
    sa.Column('id', sa.UUID(), nullable=False),
    sa.Column('owner_id', sa.UUID(), nullable=False),
    sa.Column('name', sa.String(length=255), nullable=False),
    sa.Column('description', sa.Text(), nullable=True),
    sa.Column('created_at', sa.DateTime(timezone=True), server_default=sa.text('now()'), nullable=True),
    sa.Column('updated_at', sa.DateTime(timezone=True), server_default=sa.text('now()'), nullable=True),
    sa.ForeignKeyConstraint(['owner_id'], ['users.id'], ondelete='CASCADE'),
    sa.PrimaryKeyConstraint('id')
    )
    op.create_table('refresh_tokens',
    sa.Column('id', sa.UUID(), nullable=False),
    sa.Column('user_id', sa.UUID(), nullable=False),
    sa.Column('jti', sa.UUID(), nullable=False),
    sa.Column('issued_at', sa.DateTime(timezone=True), server_default=sa.text('now()'), nullable=True),
    sa.Column('expires_at', sa.DateTime(timezone=True), nullable=False),
    sa.Column('revoked', sa.Boolean(), nullable=True),
    sa.Column('replaced_by', sa.UUID(), nullable=True),
    sa.ForeignKeyConstraint(['replaced_by'], ['refresh_tokens.id'], ),
    sa.ForeignKeyConstraint(['user_id'], ['users.id'], ondelete='CASCADE'),
    sa.PrimaryKeyConstraint('id'),
    sa.UniqueConstraint('jti')
    )
    op.create_table('documents',
    sa.Column('id', sa.UUID(), nullable=False),
    sa.Column('data_room_id', sa.UUID(), nullable=False),
    sa.Column('uploaded_by', sa.UUID(), nullable=False),
    sa.Column('filename', sa.String(length=255), nullable=False),
    sa.Column('content_type', sa.String(length=100), nullable=False),
    sa.Column('size_bytes', sa.BigInteger(), nullable=False),
    sa.Column('sha256_hash', sa.String(length=64), nullable=True),
    sa.Column('storage_key', sa.Text(), nullable=False),
    sa.Column('uploaded_at', sa.DateTime(timezone=True), server_default=sa.text('now()'), nullable=True),
    sa.ForeignKeyConstraint(['data_room_id'], ['data_rooms.id'], ondelete='CASCADE'),
    sa.ForeignKeyConstraint(['uploaded_by'], ['users.id'], ),
    sa.PrimaryKeyConstraint('id')
    )
    op.create_table('invites',
    sa.Column('id', sa.UUID(), nullable=False),
    sa.Column('data_room_id', sa.UUID(), nullable=False),
    sa.Column('token_hash', sa.String(length=64), nullable=False),
    sa.Column('created_by', sa.UUID(), nullable=False),
    sa.Column('allowed_email', sa.String(length=255), nullable=True),
    sa.Column('max_uses', sa.Integer(), nullable=True),
    sa.Column('uses_count', sa.Integer(), nullable=True),
    sa.Column('expires_at', sa.DateTime(timezone=True), nullable=True),
    sa.Column('revoked', sa.Boolean(), nullable=True),
    sa.Column('created_at', sa.DateTime(timezone=True), server_default=sa.text('now()'), nullable=True),
    sa.ForeignKeyConstraint(['created_by'], ['users.id'], ),
    sa.ForeignKeyConstraint(['data_room_id'], ['data_rooms.id'], ondelete='CASCADE'),
    sa.PrimaryKeyConstraint('id'),
    sa.UniqueConstraint('token_hash')
    )
    op.create_table('shares',
    sa.Column('id', sa.UUID(), nullable=False),
    sa.Column('data_room_id', sa.UUID(), nullable=False),
    sa.Column('user_id', sa.UUID(), nullable=False),
    sa.Column('invite_id', sa.UUID(), nullable=True),
    sa.Column('role', sa.String(length=10), nullable=False),
    sa.Column('expires_at', sa.DateTime(timezone=True), nullable=True),
    sa.Column('revoked', sa.Boolean(), nullable=True),
    sa.Column('created_at', sa.DateTime(timezone=True), server_default=sa.text('now()'), nullable=True),
    sa.ForeignKeyConstraint(['data_room_id'], ['data_rooms.id'], ondelete='CASCADE'),
    sa.ForeignKeyConstraint(['invite_id'], ['invites.id'], ),
    sa.ForeignKeyConstraint(['user_id'], ['users.id'], ondelete='CASCADE'),
    sa.PrimaryKeyConstraint('id'),
    sa.UniqueConstraint('data_room_id', 'user_id', name='uix_data_room_user')
    )
    # ### end Alembic commands ###


def downgrade() -> None:
    """Downgrade schema."""
    # ### commands auto generated by Alembic - please adjust! ###
    op.drop_table('shares')
    op.drop_table('invites')
    op.drop_table('documents')
    op.drop_table('refresh_tokens')
    op.drop_table('data_rooms')
    op.drop_table('audit_logs')
    op.drop_table('users')
    # ### end Alembic commands ###

